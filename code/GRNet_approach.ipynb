{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f981a1ef",
   "metadata": {},
   "source": [
    "# Goal Recognition as a Deep Learning Task: the GRNet Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb82f3",
   "metadata": {},
   "source": [
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525789f",
   "metadata": {},
   "source": [
    "### 1.0 Imports\n",
    "\n",
    "Python imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8cfc4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import time\n",
    "import os\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.initializers import Constant\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from os.path import join\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a3a8c",
   "metadata": {},
   "source": [
    "### 1.1 Custom Classes\n",
    "\n",
    "Various classes used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8771871d",
   "metadata": {},
   "source": [
    "#### Network classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48341cba",
   "metadata": {},
   "source": [
    "Code from \n",
    "*Yang, Z.; Yang, D.; Dyer, C.; He, X.; Smola, A. J.; and Hovy, E. H.* 2016. **Hierarchical Attention Networks for Document Classification**\n",
    "https://github.com/philipperemy/keras-attention-mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "50de033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionWeights(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        # self.init = initializers.get(Constant(value=1))\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(AttentionWeights, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        return a\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n",
    "    def get_config(self):\n",
    "        config={'step_dim':self.step_dim}\n",
    "        base_config = super(AttentionWeights, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ContextVector(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ContextVector, self).__init__(**kwargs)\n",
    "        self.features_dim = 0\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        self.features_dim = input_shape[0][-1]\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        assert len(x) == 2\n",
    "        h = x[0]\n",
    "        a = x[1]\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = h * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0][0], self.features_dim\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(ContextVector, self).get_config()\n",
    "        return dict(list(base_config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb64456",
   "metadata": {},
   "source": [
    "#### Constants class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e07012d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "    '''\n",
    "    Constants class.\n",
    "    '''\n",
    "    OBSERVATIONS = 0\n",
    "    CORRECT_GOAL = 1\n",
    "    POSSIBLE_GOALS = 2 \n",
    "    \n",
    "    SATELLITE = 0\n",
    "    LOGISTICS = 1\n",
    "    ZENOTRAVEL = 2\n",
    "    BLOCKSWORLD = 3\n",
    "    DRIVERLOG = 4\n",
    "    DEPOTS = 5\n",
    "    \n",
    "    MAX_PLAN_LENGTH = 0\n",
    "    MODEL_FILE = 1\n",
    "    DICTIONARIES_DICT = 2\n",
    "    \n",
    "    SMALL = 0\n",
    "    COMPLETE = 1\n",
    "    PERCENTAGE = 2\n",
    "    \n",
    "    MODELS_DIR = '../models/'\n",
    "    DICTIONARIES_DIR = './dictionaries/'\n",
    "    #MODELS_DIR = './incremental_models/'\n",
    "    \n",
    "    MODEL_LOGISTICS = None\n",
    "    MODEL_SATELLITE = None\n",
    "    MODEL_ZENOTRAVEL = None\n",
    "    MODEL_BLOCKSWORLS = None\n",
    "    MODEL_DRIVERLOG = None\n",
    "    MODEL_DEPOTS = None\n",
    "\n",
    "    MAX_PLAN_PERCENTAGE = 0.7\n",
    "\n",
    "    TABLE_HEADERS = ['', 'Pereira', 'Our', 'Support']\n",
    "    \n",
    "    CUSTOM_OBJECTS = {'AttentionWeights': AttentionWeights,\n",
    "                   'ContextVector' : ContextVector,\n",
    "                   'custom_multilabel_loss_v3' : BinaryCrossentropy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc128c",
   "metadata": {},
   "source": [
    "#### Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c2882311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanLengthError(Exception):\n",
    "    pass\n",
    "\n",
    "class FileFormatError(Exception):\n",
    "    pass\n",
    "\n",
    "class UnknownIndexError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871bfbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1.2 Custom Methods\n",
    "\n",
    "Various methods used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698999d5",
   "metadata": {},
   "source": [
    "#### Unpack files methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "db6ed7d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unzip_file(file_path: str, target_dir: str) -> None:\n",
    "    '''\n",
    "    Unzip a file in an empty directory. The directory is \n",
    "    emptied before the execution.\n",
    "    \n",
    "    Args:\n",
    "        file_path:\n",
    "            A string that contains the path\n",
    "            to the .zip file.\n",
    "        \n",
    "        target_dir:\n",
    "            A string that contains the path \n",
    "            to the target directory. This \n",
    "            directory is created if it doesn't\n",
    "            exist and it is emptied if it exists.\n",
    "        \n",
    "    '''\n",
    "    if os.path.exists(target_dir):\n",
    "        for f in os.listdir(target_dir):\n",
    "            os.remove(join(target_dir, f))\n",
    "        os.rmdir(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "    os.system(f'unzip -qq {file_path} -d {target_dir}')\n",
    "    \n",
    "def unpack_bz2(file_path: str, target_dir: str) -> None:\n",
    "    '''\n",
    "    Unpack a .bz2 file in an empty directory. The directory \n",
    "    is emptied before the execution.\n",
    "    \n",
    "    Args:\n",
    "        file_path:\n",
    "            A string that contains the path\n",
    "            to the .bz2 file.\n",
    "        \n",
    "        target_dir:\n",
    "            A string that contains the path \n",
    "            to the target directory. This \n",
    "            directory is created if it doesn't\n",
    "            exist and it is emptied if it exists.\n",
    "        \n",
    "    '''\n",
    "    if os.path.exists(target_dir):\n",
    "        for f in os.listdir(target_dir):\n",
    "            os.remove(join(target_dir, f))\n",
    "        os.rmdir(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "    os.system(f'tar -xf {file_path} -C {target_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a2ca8",
   "metadata": {},
   "source": [
    "#### Input parse methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d17603a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file: str, binary: bool = False, use_pickle: bool = False):\n",
    "    '''\n",
    "    Get file content from path.\n",
    "    \n",
    "    Args:\n",
    "        file:\n",
    "            A string that contains the path\n",
    "            to the file.\n",
    "        binary:\n",
    "            Optional. True if the file is a \n",
    "            binary file.\n",
    "        use_pickle:\n",
    "            Optional. True if the file was \n",
    "            saved using pickle.\n",
    "            \n",
    "    Returns:\n",
    "        The content of the file.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError:\n",
    "            An error accessing the file\n",
    "    '''\n",
    "    operation = 'r'\n",
    "    if binary:\n",
    "        operation += 'b'\n",
    "    with open(file, operation) as rf:\n",
    "        if use_pickle:\n",
    "            output = pickle.load(rf)\n",
    "        else:\n",
    "            output = rf.readlines()\n",
    "        rf.close()\n",
    "    return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7153ade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(read_file: str, content_type: int, dictionary: dict = None):\n",
    "    '''\n",
    "    Parse different input files.\n",
    "    \n",
    "    Args:\n",
    "        read_file: \n",
    "            String containing the path to the file.\n",
    "        content_type: \n",
    "            Integer representing the kind of parse to apply.\n",
    "                0: observations file,\n",
    "                1: correct goal file, \n",
    "                2: possible goals file\n",
    "        \n",
    "    Returns:\n",
    "        A list of strings that contains the parsed elements.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError: \n",
    "            An error regarding the action format in \n",
    "            the file   \n",
    "    '''\n",
    "    \n",
    "    msg_empty = f'File {read_file} is empty.'\n",
    "    msg_index = f'Content type {content_type} is unknown.' \n",
    "    \n",
    "    elements = list()\n",
    "    \n",
    "    lines = load_file(read_file)\n",
    "    if len(lines) == 0:\n",
    "        raise FileFormatError(msg_empty)\n",
    "    if content_type == C.OBSERVATIONS:\n",
    "        elements = parse_observations(lines, dictionary)\n",
    "    elif content_type == C.POSSIBLE_GOALS:\n",
    "        elements = parse_possible_goals(lines, dictionary)\n",
    "    elif content_type == C.CORRECT_GOAL:\n",
    "        elements = parse_correct_goal(lines[0], dictionary)\n",
    "    else:\n",
    "        raise UnknownIndexError(msg_index)\n",
    "    \n",
    "    if len(elements) > 0:    \n",
    "        return elements\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "        \n",
    "\n",
    "def remove_parentheses(line: str) -> str:\n",
    "    '''\n",
    "    Remove parentheses from a string.\n",
    "    \n",
    "    Args:\n",
    "        line: a string that is enclosed in parentheses.\n",
    "        For example:\n",
    "        \n",
    "        \"(string example)\"\n",
    "        \n",
    "    Returns:\n",
    "        The string without the parenteses.\n",
    "        None if the string is empty.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError: error handling the string\n",
    "    '''\n",
    "    \n",
    "    msg = (f'Error while parsing a line. Expected \"(custom '\n",
    "    +f'text)\" but found \"{line}\"')\n",
    "    \n",
    "    line = line.strip()\n",
    "    if line.startswith('(') and line.endswith(')'):\n",
    "        element = line[1:-1]\n",
    "        element = element.strip()\n",
    "        if len(element) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return element\n",
    "    elif len(line) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        raise FileFormatError(msg)\n",
    "        \n",
    "def retrieve_from_dict(key: str, dictionary: dict):\n",
    "    '''\n",
    "    Return the dictionary value given the key.\n",
    "    \n",
    "    Args:\n",
    "        key:\n",
    "            A string that is the key.\n",
    "        dictionary:\n",
    "            A dict.\n",
    "            \n",
    "    Returns:\n",
    "        The value corresponding to the key.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError:\n",
    "            An error accessing the dictionary.\n",
    "    '''\n",
    "    \n",
    "    msg_error = f'Key {key.upper()} is not in the dictionary'\n",
    "    \n",
    "    try:\n",
    "        return dictionary[key.upper()]\n",
    "    except KeyError:\n",
    "        print(msg_error)\n",
    "        np.random.seed(47)\n",
    "        return np.random.randint(0,len(dictionary))\n",
    "\n",
    "def parse_correct_goal(line: str, goals_dict: dict = None) -> list:\n",
    "    '''\n",
    "    Parse the fluents that compose a goal.\n",
    "    \n",
    "    Args:\n",
    "        line: \n",
    "            A string that contains one or more \n",
    "            fluents in the goal. Fluents are \n",
    "            enclosed in parentheses and separated\n",
    "            by commas. For example:\n",
    "            \n",
    "            \"(fluent1), (fluent2),  (fluent3)\"\n",
    "        \n",
    "        goals_dict:\n",
    "            Optional. A dictionary that maps each \n",
    "            fluent to its unique identifier.\n",
    "    \n",
    "    Returns:\n",
    "        A list of strings containing each fluent \n",
    "        without parentheses.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError:\n",
    "            An error accessing the file.\n",
    "    '''\n",
    "    msg_empty = 'Parsed goal is empty.'\n",
    "    \n",
    "    goal = list()\n",
    "    line = line.strip()\n",
    "    fluents = line.split(',')\n",
    "    for f in fluents:\n",
    "        fluent = remove_parentheses(f)\n",
    "        if fluent is not None:\n",
    "            if goals_dict is not None:\n",
    "                fluent = retrieve_from_dict(fluent, goals_dict)\n",
    "            goal.append(fluent)\n",
    "    if len(goal) > 0:\n",
    "        return goal\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "    \n",
    "\n",
    "        \n",
    "def parse_observations(lines: list, obs_dict: dict = None) -> list:\n",
    "    '''\n",
    "    Removes parentheses and empty strings from \n",
    "    the observations list.\n",
    "    \n",
    "    Args:\n",
    "        lines: \n",
    "            List of strings that contains the \n",
    "            observations. Each observation is\n",
    "            enclosed in parentheses. For \n",
    "            example:\n",
    "            \n",
    "            ['(observation1)', '', '(observation2)']\n",
    "        \n",
    "        obs_dict:\n",
    "            Optional. A dictionary that maps each \n",
    "            observation to its unique identifier.\n",
    "            \n",
    "    Returns:\n",
    "        The input list without parentheses and\n",
    "        empty strings.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError:\n",
    "            An error accessing the file.\n",
    "    '''\n",
    "    msg_empty='Observations list is empty.'\n",
    "    \n",
    "    observations = list()\n",
    "    \n",
    "    for line in lines:\n",
    "        observation = remove_parentheses(line)\n",
    "        if observation is not None:\n",
    "            if obs_dict is not None:\n",
    "                observation = retrieve_from_dict(observation, obs_dict)\n",
    "            observations.append(observation)\n",
    "    if len(observations)>0:\n",
    "        return observations\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "\n",
    "def parse_possible_goals(lines: list, goals_dict: dict = None) -> list:\n",
    "    '''\n",
    "    Parse a list of goals.\n",
    "    \n",
    "    Args:\n",
    "        lines:\n",
    "            A list of strings that contains each\n",
    "            possible goal.\n",
    "            \n",
    "        goals_dict:\n",
    "            Optional. A dictionary that maps each \n",
    "            fluent to its unique identifier.\n",
    "    \n",
    "    Returns:\n",
    "        A list of lists. Each list contains the fluents\n",
    "        that compose the goal represented as a string.\n",
    "        \n",
    "    Raises:\n",
    "        FileFormatError:\n",
    "            An error accessing the file.\n",
    "    '''\n",
    "    msg_empty='Possible goals list is empty.'\n",
    "    \n",
    "    goals=list()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if len(line)>0:\n",
    "            goals.append(parse_correct_goal(line, goals_dict))\n",
    "    if len(goals) > 0:\n",
    "        return goals\n",
    "    else:\n",
    "        raise FileFormatError(msg_empty)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a5a07",
   "metadata": {},
   "source": [
    "#### Model related methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2c1359ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_domain(domain: Union[str, int]) -> int:\n",
    "    '''\n",
    "    Converts domain name into integer\n",
    "    \n",
    "    Args:\n",
    "        domain: \n",
    "            A string or an int that represents\n",
    "            a domain.\n",
    "    \n",
    "    Returns:\n",
    "        An integer associated to a specific domain.\n",
    "        \n",
    "    Raises:\n",
    "        KeyError:\n",
    "            An error parsing the domain arg.\n",
    "    '''\n",
    "    msg = (f'Provided domain {domain} is not supported. '+\n",
    "           f'Supported domains are: {C.SATELLITE} : satellite, ' +\n",
    "           f'{C.LOGISTICS} : logistics, {C.BLOCKSWORLD} : blocksworld, ' +\n",
    "           f'{C.ZENOTRAVEL} : zenotravel, {C.DRIVERLOG}: driverlog,' + \n",
    "           f'{C.DEPOTS}: depots.')\n",
    "           \n",
    "    if (str(domain).isdigit() and int(domain) == C.SATELLITE) or str(domain).lower().strip() == 'satellite':\n",
    "        return C.SATELLITE\n",
    "    elif (str(domain).isdigit() and int(domain) == C.LOGISTICS) or str(domain).lower().strip() == 'logistics':\n",
    "        return C.LOGISTICS\n",
    "    elif (str(domain).isdigit() and int(domain) == C.BLOCKSWORLD) or str(domain).lower().strip() == 'blocksworld':\n",
    "        return C.BLOCKSWORLD\n",
    "    elif (str(domain).isdigit() and int(domain) == C.ZENOTRAVEL) or str(domain).lower().strip() == 'zenotravel':\n",
    "        return C.ZENOTRAVEL\n",
    "    elif (str(domain).isdigit() and int(domain) == C.DRIVERLOG) or str(domain).lower().strip() == 'driverlog':\n",
    "        return C.DRIVERLOG\n",
    "    elif (str(domain).isdigit() and int(domain) == C.DEPOTS) or str(domain).lower().strip() == 'depots':\n",
    "        return C.DEPOTS\n",
    "    else:\n",
    "        raise KeyError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c5de0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(domain: int):\n",
    "    '''\n",
    "    Loads the model for a specific domain.\n",
    "    \n",
    "    Args:\n",
    "        domain: \n",
    "            an integer associated to a specific \n",
    "            domain.\n",
    "            \n",
    "    Returns:\n",
    "        The Model loaded for the domain or None\n",
    "        if there is no model in memory.\n",
    "        \n",
    "    Raises:\n",
    "        KeyError:\n",
    "            An error parsing the domain arg.\n",
    "    '''\n",
    "\n",
    "    msg = (f'Provided domain {domain} is not supported. '+\n",
    "       f'Supported domains are: {C.SATELLITE} : satellite, ' +\n",
    "       f'{C.LOGISTICS} : logistics, {C.BLOCKSWORLD} : blocksworld, ' +\n",
    "       f'{C.ZENOTRAVEL} : zenotravel, {C.DRIVERLOG}: driverlog,' + \n",
    "       f'{C.DEPOTS}: depots.')\n",
    "    \n",
    "    if domain == C.LOGISTICS:\n",
    "        return C.MODEL_LOGISTICS\n",
    "    elif domain == C.SATELLITE:\n",
    "        return C.MODEL_SATELLITE\n",
    "    elif domain == C.DEPOTS:\n",
    "        return C.MODEL_DEPOTS\n",
    "    elif domain == C.BLOCKSWORLD:\n",
    "        return C.MODEL_BLOCKSWORLS\n",
    "    elif domain == C.DRIVERLOG:\n",
    "        return C.MODEL_DRIVERLOG\n",
    "    elif domain == C.ZENOTRAVEL:\n",
    "        return C.MODEL_ZENOTRAVEL\n",
    "    else:\n",
    "        raise KeyError(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3b6e6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_related(domain: int, element: int, model_type: int = C.SMALL, \n",
    "                       percentage: float = 0) -> Union[int, str]:\n",
    "    '''\n",
    "    Returns domain related information\n",
    "    \n",
    "    Args:\n",
    "        domain: \n",
    "            an integer associated to a specific \n",
    "            domain.\n",
    "        \n",
    "        element:\n",
    "            an integer associated to a specific\n",
    "            piece of information to retrieve.\n",
    "        \n",
    "        model_type:\n",
    "            an integer associated to the type\n",
    "            of RNN model in use.\n",
    "        \n",
    "        percentage:\n",
    "            a float that represents the model\n",
    "            percentage to use. Use only with\n",
    "            model_type = C.PERCENTAGE.\n",
    "    \n",
    "    Returns: \n",
    "        Max plan size if element=C.MAX_PLAN_LENGTH,\n",
    "        Model file if element=C.MODEL_FILE\n",
    "        Dictionaries directory if element=C.DICTIONARIES_DICT\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    msg = (f'Provided domain {domain} is not supported. '+\n",
    "           f'Supported domains are: {C.SATELLITE} : satellite, ' +\n",
    "           f'{C.LOGISTICS} : logistics, {C.BLOCKSWORLD} : blocksworld, ' +\n",
    "           f'{C.ZENOTRAVEL} : zenotravel.')\n",
    "    if domain == C.LOGISTICS:\n",
    "        v = {\n",
    "            'max_plan_len' : 50,\n",
    "            'name' : 'logistics',\n",
    "        }\n",
    "    elif domain == C.SATELLITE:\n",
    "        v = {\n",
    "            'max_plan_len' : 40,\n",
    "            'name' : 'satellite',\n",
    "        }\n",
    "    elif domain == C.ZENOTRAVEL:\n",
    "        v = {\n",
    "            'max_plan_len' : 40,\n",
    "            'name' : 'zenotravel',\n",
    "        }\n",
    "    elif domain == C.BLOCKSWORLD:\n",
    "        v = {\n",
    "            'max_plan_len' : 75,\n",
    "            'name' : 'blocksworld',\n",
    "        }\n",
    "    elif domain == C.DRIVERLOG:\n",
    "        v = {\n",
    "            'max_plan_len' : 70,\n",
    "            'name' : 'driverlog',\n",
    "        }\n",
    "    elif domain == C.DEPOTS:\n",
    "        v = {\n",
    "            'max_plan_len' : 64,\n",
    "            'name' : 'depots'\n",
    "        }\n",
    "    else:\n",
    "        raise KeyError(msg)\n",
    "        \n",
    "    if element == C.MAX_PLAN_LENGTH:\n",
    "        return int(v['max_plan_len']*C.MAX_PLAN_PERCENTAGE)\n",
    "    \n",
    "    elif element == C.MODEL_FILE:\n",
    "        if model_type == C.COMPLETE:\n",
    "            return f'{v[\"name\"]}.h5'\n",
    "        elif model_type == C.SMALL:\n",
    "            return f'{v[\"name\"]}_small.h5'\n",
    "        elif model_type == C.PERCENTAGE:\n",
    "            return f'{v[\"name\"]}_{int(percentage*100)}perc.h5'\n",
    "        \n",
    "    elif element == C.DICTIONARIES_DICT:\n",
    "        return join(C.DICTIONARIES_DIR, f'{v[\"name\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e6def",
   "metadata": {},
   "source": [
    "#### Domain component methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0e191963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observations_array(observations: list, max_plan_length: int) -> np.ndarray:\n",
    "    '''\n",
    "    Create an array of observations index.\n",
    "    \n",
    "    Args:\n",
    "        observations: \n",
    "            A list of action names\n",
    "            \n",
    "        max_plan_length:\n",
    "            An integer that contains the maximum size of\n",
    "            the list that will be considered.\n",
    "    \n",
    "    Returns:\n",
    "        An array that contains the observations' indexes\n",
    "    '''\n",
    "    \n",
    "    WARNING_MSG = (f'The action trace is too long. Only the first {max_plan_length}'+\n",
    "                 f'actions will be considered.')\n",
    "    \n",
    "    observations_array = np.zeros((1, max_plan_length))\n",
    "    if len(observations) > max_plan_length:\n",
    "        pass\n",
    "        # print(WARNING_MSG)\n",
    "    for index, observation in enumerate(observations):\n",
    "        if index < max_plan_length:\n",
    "            observations_array[0][index] = int(observation)\n",
    "    return observations_array\n",
    "        \n",
    "\n",
    "def get_predictions(observations: list, \n",
    "                    max_plan_length: int, \n",
    "                    domain: int) -> np.ndarray:\n",
    "    '''\n",
    "    Return the model predictions.\n",
    "    \n",
    "    Args:\n",
    "        observations:\n",
    "            A list of action names.\n",
    "        \n",
    "        max_plan_length:\n",
    "            An integer that contains the maximum size of\n",
    "            the list that will be considered.\n",
    "        \n",
    "        domain:\n",
    "            An integer associated to a specific domain.\n",
    "    \n",
    "    Returns:\n",
    "        The model predictions.\n",
    "    '''\n",
    "\n",
    "    model = get_model(domain)\n",
    "    \n",
    "    model_input = tf.convert_to_tensor(get_observations_array(observations, max_plan_length))\n",
    "    y_pred = model.predict(model_input)\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62884125",
   "metadata": {},
   "source": [
    "#### GR Instance component methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f14f6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(prediction: np.ndarray, possible_goal: list) -> float:\n",
    "    '''\n",
    "    Returns the score for a possible goal.\n",
    "    \n",
    "    Args:\n",
    "        prediction:\n",
    "            An array that contains the model prediction.\n",
    "        \n",
    "        possible_goal:\n",
    "            A list that contains the possible goal indexes.\n",
    "        \n",
    "    Returns:\n",
    "        An float that represents the score of the possible goal.\n",
    "    '''\n",
    "    \n",
    "    score=0\n",
    "    \n",
    "    for index in possible_goal:\n",
    "        score += prediction[0][int(index)]\n",
    "    return score\n",
    "\n",
    "def get_scores(prediction: np.ndarray, possible_goals: list) -> np.ndarray:\n",
    "    '''\n",
    "    Returns the scores for all possible goals.\n",
    "    \n",
    "    Args:\n",
    "        prediction:\n",
    "            An array that contains the model prediction.\n",
    "        \n",
    "        possible_goals:\n",
    "            A list of possible goals; each possible goal is represented as a\n",
    "            list\n",
    "        \n",
    "    Returns:\n",
    "        An array that contains the score of each of the possible goals.\n",
    "    '''\n",
    "    scores = np.zeros((len(possible_goals, )), dtype=float)\n",
    "    for index, possible_goal in enumerate(possible_goals):\n",
    "        scores[index] = get_score(prediction, possible_goal)\n",
    "    return scores\n",
    "        \n",
    "\n",
    "def get_max(scores: np.ndarray) -> list:\n",
    "    '''\n",
    "    Returns a list with the index (or indexes) of the highest scores.\n",
    "    \n",
    "    Args:\n",
    "        scores:\n",
    "            An array that contains the scores as floats.\n",
    "    \n",
    "    Returns:\n",
    "        A list thet contains the indexes of the highest score.\n",
    "    '''\n",
    "    max_element = -1\n",
    "    index_max = list()\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > max_element:\n",
    "            max_element = scores[i]\n",
    "            index_max = [i]\n",
    "        elif scores[i] == max_element:\n",
    "            index_max.append(i)\n",
    "\n",
    "    return index_max\n",
    "    \n",
    "def get_result(scores: np.ndarray, correct_goal: int) -> bool:\n",
    "    '''\n",
    "    Computes if the goal recognition task is successfull.\n",
    "    \n",
    "    Args:\n",
    "        scores:\n",
    "            An array of floats that contains a score for \n",
    "            each possible goal\n",
    "        correct_goal: \n",
    "            An integer that represents the index of the \n",
    "            correct goal\n",
    "            \n",
    "    Returns:\n",
    "        True if the maximum score index corresponds to the \n",
    "        correct goal index, False otherwise.\n",
    "    '''\n",
    "    idx_max_list = get_max(scores)\n",
    "    if len(idx_max_list) == 1:\n",
    "        idx_max = idx_max_list[0]\n",
    "    else:\n",
    "        # print(f'Algorithm chose randomly one of {len(idx_max_list)} equals candidates.')\n",
    "        idx_max = idx_max_list[np.random.randint(0, len(idx_max_list))]\n",
    "    if idx_max == correct_goal:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_correct_goal_idx(correct_goal: list, possible_goals: list) -> int:\n",
    "    '''\n",
    "    Conputes the correct goal index.\n",
    "    \n",
    "    Args:\n",
    "        correct_goal:\n",
    "            A list of strings that contains the correct goal\n",
    "            fluents.\n",
    "        possible_goals:\n",
    "            A list of possible goals; each possible goal is represented as a\n",
    "            list.\n",
    "    \n",
    "    Returns:\n",
    "        The index of the correct goal in the possible goals list.\n",
    "        None if the possible goal list does not contain the correct goal.\n",
    "    '''\n",
    "    \n",
    "    for index, possible_goal in enumerate(possible_goals):\n",
    "        possible_goal = np.sort(possible_goal)\n",
    "        correct_goal = np.sort(correct_goal)\n",
    "        if np.all(possible_goal == correct_goal):\n",
    "            return index\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16711946",
   "metadata": {},
   "source": [
    "#### GRNet execution methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3f87cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_models(model_type: int, percentage: float)-> None:\n",
    "    '''\n",
    "    Loads in memory all the models.\n",
    "    \n",
    "    Args:\n",
    "        model_type:\n",
    "            an integer associated to the type\n",
    "            of RNN model in use.\n",
    "        \n",
    "        percentage:\n",
    "            a float that represents the model\n",
    "            percentage to use. Use only with\n",
    "            model_type = C.PERCENTAGE.\n",
    "    \n",
    "    Returns:\n",
    "        None   \n",
    "    '''\n",
    "    \n",
    "    model_file = get_domain_related(C.LOGISTICS, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_LOGISTICS =  load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.SATELLITE, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_SATELLITE = load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.ZENOTRAVEL, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_ZENOTRAVEL = load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.DEPOTS, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_DEPOTS = load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.DRIVERLOG, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_DRIVERLOG =  load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)\n",
    "    \n",
    "    model_file = get_domain_related(C.BLOCKSWORLD, C.MODEL_FILE, model_type=model_type, percentage=percentage)\n",
    "    C.MODEL_BLOCKSWORLS =  load_model(join(C.MODELS_DIR, model_file), custom_objects=C.CUSTOM_OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "06eb9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(obs_file: str, \n",
    "            goals_dict_file: Union[str, None],\n",
    "            actions_dict_file: Union[str, None],\n",
    "            possible_goals_file: str, \n",
    "            correct_goal_file: str, \n",
    "            domain: Union[str, int], \n",
    "            verbose: int = 0) -> list:\n",
    "    '''\n",
    "    Run the goal recognition experiment\n",
    "\n",
    "    Args:\n",
    "        obs_file:\n",
    "            Path of the file that contains the\n",
    "            observations (plan)\n",
    "\n",
    "        goals_dict_file:\n",
    "            Path of the file that contains the\n",
    "            goals dictionaries. If None it is\n",
    "            retrieved from its default location.\n",
    "\n",
    "        actions_dict_file:\n",
    "            Path of the file that contains the\n",
    "            actions dictionaries. If None it is\n",
    "            retrieved from its default location.\n",
    "\n",
    "        possible_goals_file:\n",
    "            Path of the file that contains the\n",
    "            possible goals.\n",
    "\n",
    "        correct_goal_file:\n",
    "            Path of the file that contains the\n",
    "            correct goal.\n",
    "\n",
    "        domain:\n",
    "            String that contains the name of the\n",
    "            domain or integer that corresponds to\n",
    "            a domain.\n",
    "\n",
    "        verbose:\n",
    "            Integer that corresponds to how much\n",
    "            information is printed. 0 = no info,\n",
    "            2 = max info\n",
    "\n",
    "    Returns:\n",
    "         A list that contains the result, the correct\n",
    "         goal index and the predicted goal index.\n",
    "    '''\n",
    "\n",
    "    domain = parse_domain(domain)\n",
    "    if goals_dict_file is None:\n",
    "        goals_dict_file = join(get_domain_related(domain, C.DICTIONARIES_DICT), 'dizionario_goal')\n",
    "    goals_dict = load_file(goals_dict_file, binary=True, use_pickle=True)\n",
    "    if actions_dict_file is None:\n",
    "        actions_dict_file = join(get_domain_related(domain, C.DICTIONARIES_DICT), 'dizionario')\n",
    "    actions_dict = load_file(actions_dict_file, binary=True, use_pickle=True)\n",
    "    observations = parse_file(obs_file, C.OBSERVATIONS, actions_dict)\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print('Observed actions:\\n')\n",
    "        for o in observations:\n",
    "            print(o)\n",
    "    possible_goals = parse_file(possible_goals_file, C.POSSIBLE_GOALS, goals_dict)\n",
    "    \n",
    "    max_plan_length = get_domain_related(domain, C.MAX_PLAN_LENGTH)\n",
    "    predictions = get_predictions(observations, max_plan_length, domain)\n",
    "    scores = get_scores(predictions, possible_goals)\n",
    "    if verbose > 0:\n",
    "        for index, goal in enumerate(possible_goals):\n",
    "            print(f'{index} - {goal} : {scores[index]}')\n",
    "    \n",
    "    correct_goal = parse_file(correct_goal_file, C.CORRECT_GOAL, goals_dict) \n",
    "    correct_goal_idx = get_correct_goal_idx(correct_goal, possible_goals)\n",
    "    result = get_result(scores, correct_goal_idx)\n",
    "    if verbose > 0:\n",
    "        print(f'Predicted goal is {get_max(scores)[0]}')\n",
    "        print(f'Correct goal is {correct_goal_idx} - {correct_goal}')\n",
    "    return [result, correct_goal_idx, get_max(scores)[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512dc1b4",
   "metadata": {},
   "source": [
    "### 1.3 Base Configurations\n",
    "Various configurations, all main parameters can be adjusted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "caedd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain\n",
    "DOMAIN = C.BLOCKSWORLD\n",
    "DOMAIN_NAME = 'blocksworld'\n",
    "\n",
    "# Paths to testsets and reports\n",
    "TS_DIR = 'TS_Per' # Either 'TS_PerGen' or 'TS_Per'\n",
    "ORIGINAL_DOMAIN_DIR = f'../testsets/{TS_DIR}/{DOMAIN_NAME}'\n",
    "NOISY_DOMAIN_DIR = f'../testsets/{TS_DIR}_noisy/{DOMAIN_NAME}/{DOMAIN_NAME}-noisy'\n",
    "REPORT_DIR = f'../testsets/{TS_DIR}_noisy/{DOMAIN_NAME}/report/{DOMAIN_NAME}-noisy'\n",
    "\n",
    "# Evaluation results paths\n",
    "ORIGINAL_RESULTS_DIR = f'../results/{TS_DIR}/{DOMAIN_NAME}'\n",
    "NOISY_RESULTS_DIR = f'../results/{TS_DIR}_noisy/{DOMAIN_NAME}'\n",
    "\n",
    "# Temporary directory to unzip files\n",
    "TEMP_DIR = f'./files_temp_dir'\n",
    "\n",
    "# Additional configs\n",
    "VERBOSE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de47d2a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **2. GRNet execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753a3fb",
   "metadata": {},
   "source": [
    "### 2.0 Common Configurations & Functions\n",
    "\n",
    "Configurations and functions specific to the execution of GRNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "34174acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change these values\n",
    "model_type=C.SMALL \n",
    "percentage=0\n",
    "\n",
    "init_models(model_type=model_type, percentage=percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9d2d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_domain(\n",
    "    domain: int,\n",
    "    domain_dir: str,\n",
    "    temp_dir: str = './files_temp_dir',\n",
    "    perc_list: List[float] = [0.1, 0.3, 0.5, 0.7, 1],\n",
    "    verbose: int = 0\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    '''\n",
    "    Process a domain for different observation percentages.\n",
    "    \n",
    "    Args:\n",
    "        domain:\n",
    "            An integer associated to a specific domain.\n",
    "        \n",
    "        domain_dir:\n",
    "            A string that contains the path to the\n",
    "            directory that contains the testset.\n",
    "        \n",
    "        temp_dir:\n",
    "            A string that contains the path to a temporary\n",
    "            directory to extract files to.\n",
    "        \n",
    "        perc_list:\n",
    "            Optional. A list of floats that contains the\n",
    "            observation percentages to process.\n",
    "        \n",
    "        verbose:\n",
    "            Optional. An integer that corresponds to how much\n",
    "            information is printed. 0 = no info, 1 = max info.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary where each key is a string representing\n",
    "        the observation percentage and each value is a DataFrame\n",
    "        that contains the results for that observation percentage.\n",
    "    '''\n",
    "    results = {}\n",
    "    times = list()\n",
    "    for perc in perc_list:\n",
    "        plans_dir = f'{join(domain_dir, str(int(perc*100)))}'\n",
    "        files = os.listdir(plans_dir)\n",
    "        total=0\n",
    "        correct=0\n",
    "        rows = []\n",
    "\n",
    "        domain_name = os.path.basename(domain_dir)\n",
    "        for j, f in enumerate(tqdm(files, desc=f'[{domain_name}][{int(perc*100)}%] Processing plans', unit='plans')): \n",
    "            obs_dir = join(plans_dir, f)\n",
    "            problem_name = f\n",
    "            if verbose:\n",
    "                print(f\"File: {f}\")\n",
    "            if f.endswith('.zip'):\n",
    "                unzip_file(join(plans_dir,f), temp_dir)\n",
    "                obs_dir = temp_dir\n",
    "                problem_name = f[:-4]\n",
    "            elif f.endswith('.bz2'):\n",
    "                unpack_bz2(join(plans_dir,f), temp_dir)\n",
    "                obs_dir = temp_dir\n",
    "                problem_name = f[:-4]\n",
    "            start_time = time.time()\n",
    "            result = run_experiment(obs_file=join(obs_dir, 'obs.dat'),\n",
    "                                    goals_dict_file=None,\n",
    "                                    actions_dict_file=None,\n",
    "                                    possible_goals_file=join(obs_dir, 'hyps.dat'),\n",
    "                                    correct_goal_file=join(obs_dir, 'real_hyp.dat'),\n",
    "                                    domain=domain, \n",
    "                                    verbose=verbose)\n",
    "            exec_time = time.time()-start_time\n",
    "            if result[0]:\n",
    "                correct+=1\n",
    "            total +=1\n",
    "            times.append(exec_time)\n",
    "            if verbose:\n",
    "                print(f'Execution time: {exec_time} seconds')\n",
    "            rows.append({\n",
    "                'problem': problem_name,\n",
    "                'correct_goal_idx': result[1],\n",
    "                'predicted_goal_idx': result[2]\n",
    "            })\n",
    "\n",
    "        results_df = pd.DataFrame(rows)\n",
    "        results[f\"{int(perc*100)}\"] = results_df\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "eb76d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_noisy_domain(\n",
    "    domain: int,\n",
    "    domain_dir: str,\n",
    "    temp_dir: str = './files_temp_dir',\n",
    "    perc_list: List[float] = [0.1, 0.3, 0.5, 0.7, 1],\n",
    "    noise_perc_list: List[float] = [0.05, 0.1, 0.2, 0.3],\n",
    "    verbose: int = 0\n",
    ") -> Dict[str, Dict[str, pd.DataFrame]]:\n",
    "    '''\n",
    "    Process a noisy domain for different observation percentages and noise levels.\n",
    "    \n",
    "    Args:\n",
    "        domain:\n",
    "            An integer associated to a specific domain.\n",
    "        \n",
    "        domain_dir:\n",
    "            A string that contains the path to the\n",
    "            directory that contains the testset. The inner\n",
    "            directories (the ones named after noise levels)\n",
    "            must have the noise level as a suffix (for example, \n",
    "            '_5' for 5% noise, '_10' for 10% noise, etc.).\n",
    "        \n",
    "        temp_dir:\n",
    "            A string that contains the path to a temporary\n",
    "            directory to extract files to.\n",
    "        \n",
    "        perc_list:\n",
    "            Optional. A list of floats that contains the\n",
    "            observation percentages to process.\n",
    "        \n",
    "        noise_perc_list:\n",
    "            Optional. A list of floats that contains the\n",
    "            noise levels to process.\n",
    "        \n",
    "        verbose:\n",
    "            Optional. An integer that corresponds to how much\n",
    "            information is printed. 0 = no info, 1 = max info.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary where each key is a string representing\n",
    "        the observation percentage and each value is another\n",
    "        dictionary. In this second dictionary, each key is a\n",
    "        string representing the noise level and each value is\n",
    "        a DataFrame that contains the results for that noise\n",
    "        level.\n",
    "    '''\n",
    "    results = {}\n",
    "    for noise in noise_perc_list:\n",
    "        noise_dir = f'{domain_dir}_{int(noise*100)}'\n",
    "        print(f'=== Processing noise level: {int(noise*100)}% ===')\n",
    "        results[f\"{int(noise*100)}\"] = process_domain(\n",
    "            domain,\n",
    "            noise_dir,\n",
    "            temp_dir=temp_dir,\n",
    "            perc_list=perc_list,\n",
    "            verbose=verbose\n",
    "        )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e436ed",
   "metadata": {},
   "source": [
    "### 2.1 Execution | Original dataset\n",
    "\n",
    "Domain processing and result saving of the original dataset (without noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "eae37ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[blocksworld][10%] Processing plans:   0%|          | 0/246 [00:00<?, ?plans/s]/tmp/ipykernel_280900/2038651677.py:112: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if np.all(possible_goal == correct_goal):\n",
      "[blocksworld][10%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 51.56plans/s]\n",
      "[blocksworld][30%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.08plans/s]\n",
      "[blocksworld][50%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.84plans/s]\n",
      "[blocksworld][70%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.14plans/s]\n",
      "[blocksworld][100%] Processing plans: 100%|██████████| 92/92 [00:01<00:00, 53.75plans/s]\n"
     ]
    }
   ],
   "source": [
    "original_results = process_domain(\n",
    "    domain=DOMAIN,\n",
    "    domain_dir=ORIGINAL_DOMAIN_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2d7ee2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>correct_goal_idx</th>\n",
       "      <th>predicted_goal_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>block-words_p01_hyp-2_full</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>block-words_p03_hyp-12_full</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>block-words_p07_hyp-4_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>block-words_p01_hyp-8_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>block-words_p01_hyp-11_full</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       problem  correct_goal_idx  predicted_goal_idx\n",
       "0   block-words_p01_hyp-2_full                 2                   2\n",
       "1  block-words_p03_hyp-12_full                12                  12\n",
       "2   block-words_p07_hyp-4_full                 8                   8\n",
       "3   block-words_p01_hyp-8_full                 8                   8\n",
       "4  block-words_p01_hyp-11_full                11                  11"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_results[\"100\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4b46b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance dataframes with additional information coming from the respective 'overall-report.csv' files.\n",
    "# Convert the problem name correctly to match the names in the report files, referring to the '100'\n",
    "# (for TS_PerGen) or 'full' (for TS_Per) observation percentage, for example:\n",
    "# TS_PerGen: 'blocksworld_p001053_hyp=3_100' -> 100/blocksworld_p001053_hyp=3_100\n",
    "# TS_Per: 'blocksworld_p001053_hyp=3_full' -> 100/blocksworld_p001053_hyp=3_full\n",
    "combined_results = {}\n",
    "for perc, df in original_results.items():\n",
    "    # Take from the 30% noisy report (could be any, we are only interested in the action counts)\n",
    "    report_path = join(f'{REPORT_DIR}_30', 'overall-report.csv')\n",
    "    report_df = pd.read_csv(report_path, delimiter=';')\n",
    "\n",
    "    enhanced_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        instance_name = f\"{perc}/{row['problem']}\"\n",
    "        matching_report = report_df[report_df['Instance'] == instance_name]\n",
    "\n",
    "        if not matching_report.empty:\n",
    "            report_row = matching_report.iloc[0]\n",
    "            enhanced_row = row.to_dict()\n",
    "            enhanced_row['num_actions'] = report_row['# Actions']\n",
    "            enhanced_rows.append(enhanced_row)\n",
    "        else:\n",
    "            raise ValueError(f\"No matching report entry for problem {row['problem']}\")\n",
    "    \n",
    "    combined_results[perc] = pd.DataFrame(enhanced_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d01147df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>correct_goal_idx</th>\n",
       "      <th>predicted_goal_idx</th>\n",
       "      <th>num_actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>block-words_p01_hyp-2_full</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>block-words_p03_hyp-12_full</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>block-words_p07_hyp-4_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>block-words_p01_hyp-8_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>block-words_p01_hyp-11_full</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       problem  correct_goal_idx  predicted_goal_idx  \\\n",
       "0   block-words_p01_hyp-2_full                 2                   2   \n",
       "1  block-words_p03_hyp-12_full                12                  12   \n",
       "2   block-words_p07_hyp-4_full                 8                   8   \n",
       "3   block-words_p01_hyp-8_full                 8                   8   \n",
       "4  block-words_p01_hyp-11_full                11                  11   \n",
       "\n",
       "   num_actions  \n",
       "0            6  \n",
       "1            8  \n",
       "2           58  \n",
       "3           10  \n",
       "4           10  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results[\"100\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "852febce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the output directory exists\n",
    "os.makedirs(ORIGINAL_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Save results to individual CSV files\n",
    "for perc, df in combined_results.items():\n",
    "    output_path = join(ORIGINAL_RESULTS_DIR, f'obs_{perc}.csv')\n",
    "    df = df.sort_values(by='problem').reset_index(drop=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "# Save to unique file (add observation percentage column)\n",
    "unique_df = [\n",
    "    df.assign(observation_percentage=int(perc))\n",
    "    for perc, df in combined_results.items()\n",
    "]\n",
    "unique_df = pd.concat(unique_df, ignore_index=True)\n",
    "unique_output_path = join(ORIGINAL_RESULTS_DIR, 'full.csv')\n",
    "unique_df = unique_df.sort_values(by=['observation_percentage', 'problem']).reset_index(drop=True)\n",
    "unique_df.to_csv(unique_output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721c01f",
   "metadata": {},
   "source": [
    "### 2.2 Execution | Noisy dataset\n",
    "\n",
    "Domain processing and result saving of the noisy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "01bc6c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing noise level: 5% ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[blocksworld-noisy_5][10%] Processing plans:   0%|          | 0/246 [00:00<?, ?plans/s]/tmp/ipykernel_280900/2038651677.py:112: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if np.all(possible_goal == correct_goal):\n",
      "[blocksworld-noisy_5][10%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 53.46plans/s]\n",
      "[blocksworld-noisy_5][30%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.53plans/s]\n",
      "[blocksworld-noisy_5][50%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 54.24plans/s]\n",
      "[blocksworld-noisy_5][70%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 49.85plans/s]\n",
      "[blocksworld-noisy_5][100%] Processing plans: 100%|██████████| 92/92 [00:01<00:00, 51.27plans/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing noise level: 10% ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[blocksworld-noisy_10][10%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.62plans/s]\n",
      "[blocksworld-noisy_10][30%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.58plans/s]\n",
      "[blocksworld-noisy_10][50%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 54.01plans/s]\n",
      "[blocksworld-noisy_10][70%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.58plans/s]\n",
      "[blocksworld-noisy_10][100%] Processing plans: 100%|██████████| 92/92 [00:01<00:00, 49.12plans/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing noise level: 20% ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[blocksworld-noisy_20][10%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 53.68plans/s]\n",
      "[blocksworld-noisy_20][30%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 53.50plans/s]\n",
      "[blocksworld-noisy_20][50%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 53.39plans/s]\n",
      "[blocksworld-noisy_20][70%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 53.87plans/s]\n",
      "[blocksworld-noisy_20][100%] Processing plans: 100%|██████████| 92/92 [00:01<00:00, 50.84plans/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing noise level: 30% ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[blocksworld-noisy_30][10%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 52.92plans/s]\n",
      "[blocksworld-noisy_30][30%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 54.11plans/s]\n",
      "[blocksworld-noisy_30][50%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 53.08plans/s]\n",
      "[blocksworld-noisy_30][70%] Processing plans: 100%|██████████| 246/246 [00:04<00:00, 54.43plans/s]\n",
      "[blocksworld-noisy_30][100%] Processing plans: 100%|██████████| 92/92 [00:01<00:00, 53.81plans/s]\n"
     ]
    }
   ],
   "source": [
    "noisy_results = process_noisy_domain(\n",
    "    domain=C.BLOCKSWORLD,\n",
    "    domain_dir=NOISY_DOMAIN_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "85f4f638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>correct_goal_idx</th>\n",
       "      <th>predicted_goal_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>block-words_p01_hyp-2_full</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>block-words_p03_hyp-12_full</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>block-words_p07_hyp-4_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>block-words_p01_hyp-8_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>block-words_p01_hyp-11_full</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       problem  correct_goal_idx  predicted_goal_idx\n",
       "0   block-words_p01_hyp-2_full                 2                   2\n",
       "1  block-words_p03_hyp-12_full                12                  12\n",
       "2   block-words_p07_hyp-4_full                 8                   8\n",
       "3   block-words_p01_hyp-8_full                 8                   8\n",
       "4  block-words_p01_hyp-11_full                11                  11"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_results[\"5\"][\"100\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1c539bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance dataframes with additional information coming from the respective 'overall-report.csv' files.\n",
    "# Convert the problem name correctly to match the names in the report files, for example:\n",
    "# 'blocksworld_p001053_hyp=3_100' -> 100/blocksworld_p001053_hyp=3_100\n",
    "combined_results = {}\n",
    "for noise_level, perc_dict in noisy_results.items():\n",
    "    for perc, df in perc_dict.items():\n",
    "        report_path = join(f'{REPORT_DIR}_{noise_level}', 'overall-report.csv')\n",
    "        report_df = pd.read_csv(report_path, delimiter=';')\n",
    "\n",
    "        enhanced_rows = []\n",
    "        for _, row in df.iterrows():\n",
    "            instance_name = f\"{perc}/{row['problem']}\"\n",
    "            matching_report = report_df[report_df['Instance'] == instance_name]\n",
    "\n",
    "            if not matching_report.empty:\n",
    "                report_row = matching_report.iloc[0]\n",
    "                enhanced_row = row.to_dict()\n",
    "                enhanced_row['num_actions'] = report_row['# Actions']\n",
    "                enhanced_row['num_modified_actions'] = report_row['# Modified actions']\n",
    "                enhanced_row['noise_applied'] = report_row['Noise applied']\n",
    "                enhanced_rows.append(enhanced_row)\n",
    "            else:\n",
    "                raise ValueError(f\"No matching report entry for problem {row['problem']}\")\n",
    "        \n",
    "        combined_results.setdefault(noise_level, {})[perc] = pd.DataFrame(enhanced_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9ee98e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>correct_goal_idx</th>\n",
       "      <th>predicted_goal_idx</th>\n",
       "      <th>num_actions</th>\n",
       "      <th>num_modified_actions</th>\n",
       "      <th>noise_applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>block-words_p01_hyp-2_full</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>block-words_p03_hyp-12_full</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>block-words_p07_hyp-4_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>block-words_p01_hyp-8_full</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>block-words_p01_hyp-11_full</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       problem  correct_goal_idx  predicted_goal_idx  \\\n",
       "0   block-words_p01_hyp-2_full                 2                   2   \n",
       "1  block-words_p03_hyp-12_full                12                  12   \n",
       "2   block-words_p07_hyp-4_full                 8                   8   \n",
       "3   block-words_p01_hyp-8_full                 8                   8   \n",
       "4  block-words_p01_hyp-11_full                11                  11   \n",
       "\n",
       "   num_actions  num_modified_actions  noise_applied  \n",
       "0            6                     0       0.000000  \n",
       "1            8                     1       0.125000  \n",
       "2           58                     3       0.051724  \n",
       "3           10                     0       0.000000  \n",
       "4           10                     0       0.000000  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results[\"5\"][\"100\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b7082e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the output directory exists\n",
    "os.makedirs(NOISY_RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Save results to individual CSV files\n",
    "for noise_level, perc_dict in combined_results.items():\n",
    "    for perc, df in perc_dict.items():\n",
    "        output_path = join(NOISY_RESULTS_DIR, f'noise_{noise_level}_obs_{perc}.csv')\n",
    "        df = df.sort_values(by='problem').reset_index(drop=True)\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "# Save to unique file (add observation percentage and noise percentage columns)\n",
    "unique_df = [\n",
    "    df.assign(\n",
    "        observation_percentage=int(perc),\n",
    "        noise_percentage=int(noise_level)\n",
    "    )\n",
    "    for noise_level, perc_dict in combined_results.items()\n",
    "    for perc, df in perc_dict.items()\n",
    "]\n",
    "unique_df = pd.concat(unique_df, ignore_index=True)\n",
    "unique_output_path = join(NOISY_RESULTS_DIR, f'full.csv')\n",
    "unique_df = unique_df.sort_values(by=['noise_percentage', 'observation_percentage', 'problem']).reset_index(drop=True)\n",
    "unique_df.to_csv(unique_output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4426211",
   "metadata": {},
   "source": [
    "## **3. GRNet Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dae0b5",
   "metadata": {},
   "source": [
    "### 3.1 Evaluation | Original dataset\n",
    "\n",
    "Original dataset statistics and graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ff2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full results dataframe\n",
    "original_full_df = pd.read_csv(join(ORIGINAL_RESULTS_DIR, 'full.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5f4266f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_percentage</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.491870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.707317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>0.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.945652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation_percentage  accuracy\n",
       "0                     10  0.195122\n",
       "1                     30  0.491870\n",
       "2                     50  0.707317\n",
       "3                     70  0.878049\n",
       "4                    100  0.945652"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract final results for observation percentage\n",
    "original_accuracy_df = pd.DataFrame(columns=['observation_percentage', 'accuracy'])\n",
    "for perc in original_full_df['observation_percentage'].unique():\n",
    "    obs_results = original_full_df[original_full_df['observation_percentage'] == perc]\n",
    "    accuracy = accuracy_score(obs_results['correct_goal_idx'], obs_results['predicted_goal_idx'])\n",
    "    original_accuracy_df = pd.concat([original_accuracy_df, pd.DataFrame({'observation_percentage': [perc], 'accuracy': [accuracy]})], ignore_index=True)\n",
    "\n",
    "original_accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61794f",
   "metadata": {},
   "source": [
    "### 3.2 Evaluation | Noisy dataset\n",
    "\n",
    "Noisy dataset statistics and graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "60026dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full results dataframe\n",
    "noisy_full_df = pd.read_csv(join(NOISY_RESULTS_DIR, 'full.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2c7b8d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_percentage</th>\n",
       "      <th>observation_percentage</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.186992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.471545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.646341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.182927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.443089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.589431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.182927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.378049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>0.569106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.880435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.386179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>0.467480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>70</td>\n",
       "      <td>0.605691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>0.706522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_percentage observation_percentage  accuracy\n",
       "0                 5                     10  0.186992\n",
       "1                 5                     30  0.471545\n",
       "2                 5                     50  0.646341\n",
       "3                 5                     70  0.804878\n",
       "4                 5                    100  0.934783\n",
       "5                10                     10  0.182927\n",
       "6                10                     30  0.443089\n",
       "7                10                     50  0.589431\n",
       "8                10                     70  0.804878\n",
       "9                10                    100  0.847826\n",
       "10               20                     10  0.182927\n",
       "11               20                     30  0.378049\n",
       "12               20                     50  0.569106\n",
       "13               20                     70  0.666667\n",
       "14               20                    100  0.880435\n",
       "15               30                     10  0.166667\n",
       "16               30                     30  0.386179\n",
       "17               30                     50  0.467480\n",
       "18               30                     70  0.605691\n",
       "19               30                    100  0.706522"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract final results for observation percentage and noise level\n",
    "noisy_accuracy_df = pd.DataFrame(columns=['noise_percentage', 'observation_percentage', 'accuracy'])\n",
    "for noise_level in noisy_full_df['noise_percentage'].unique():\n",
    "    noise_results = noisy_full_df[noisy_full_df['noise_percentage'] == noise_level]\n",
    "    for perc in noise_results['observation_percentage'].unique():\n",
    "        obs_results = noise_results[noise_results['observation_percentage'] == perc]\n",
    "        accuracy = accuracy_score(obs_results['correct_goal_idx'], obs_results['predicted_goal_idx'])\n",
    "        noisy_accuracy_df = pd.concat([noisy_accuracy_df, pd.DataFrame({'noise_percentage': [noise_level], 'observation_percentage': [perc], 'accuracy': [accuracy]})], ignore_index=True)\n",
    "\n",
    "noisy_accuracy_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
